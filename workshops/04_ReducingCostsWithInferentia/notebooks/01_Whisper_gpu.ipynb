{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3edd743f-76e0-47c4-9603-d2debae87fac",
   "metadata": {},
   "source": [
    "# Deploying models using AWS Trainium and AWS Inferentia2 to reduce cost\n",
    "Whisper is a state-of-the-art model for automatic speech recognition (ASR) and speech translation, proposed in the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford et al. from OpenAI. It available on [Huggingface](https://huggingface.co/openai/whisper-large-v3) and we will use it to demonstrate various approaches to deploy it and how we can use AWS Inferentia2 to achive better cost performance.\n",
    "\n",
    "First let's install required libraries and download sample file that we gonna use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c207e-3c22-44cc-a80d-abd16ff526e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U sagemaker librosa\n",
    "!wget --no-check-certificate https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b097e-4d16-4266-8542-f7d7ff66e1a6",
   "metadata": {},
   "source": [
    "Remember to restart kernel after installing dependencies. Next let's estabilish sagemaker session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da4d16-57a2-4c96-a67d-56709db7b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'us-east-1'\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "session = sagemaker.Session(boto_session=boto3.Session(region_name=region))\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae5925-0b92-40d8-9f26-b0d3083d0a80",
   "metadata": {},
   "source": [
    "## Deploying Whisper on Amazon SageMaker Endpoint using gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfd453-5f1b-41f7-9616-b08a412ae5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'openai/whisper-large-v3',\n",
    "\t'HF_TASK':'automatic-speech-recognition'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\ttransformers_version='4.49.0',\n",
    "\tpytorch_version='2.6.0',\n",
    "\tpy_version='py312',\n",
    "\tenv=hub,\n",
    "\trole=role,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f119326-3a74-41da-98e6-8b5fd9d5748b",
   "metadata": {},
   "source": [
    "For later cost performance comparison we will use G5 instance. You can also try to use newest version G6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffc95b-9c7d-4963-8f4d-f92941e4eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type='ml.g5.xlarge'\n",
    "#instance_type='ml.g6.xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf09968-79d2-4abf-a499-fdd3a2f4dd0f",
   "metadata": {},
   "source": [
    "Deploy model to SageMaker Inference, it will roughly take 8-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3206f-e518-49bb-8216-d1fdefcee63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1, # number of instances\n",
    "\tinstance_type=instance_type # ec2 instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b8e757-b09a-4253-b1e2-851fb77c054b",
   "metadata": {},
   "source": [
    "If by any chance your notebook looses conection and the endpoint is succesfully deployed you can create the predictor using name obtained from the console. Just uncomment these lines and fill in the endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e72707-27df-43b0-a80c-021b4f43f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.predictor import Predictor\n",
    "# predictor = Predictor(\n",
    "#     endpoint_name=\"YOUR_ENDPOINT_NAME\",\n",
    "#     sagemaker_session=session\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b351ae41-61ea-4966-9e3a-31f67caf03e0",
   "metadata": {},
   "source": [
    "Let's configure serializers for input and output. Input is an audio file and output it's transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1730f-9b02-4bb0-a0e3-7945d135dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import DataSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\t\n",
    "\n",
    "predictor.serializer = DataSerializer(content_type='audio/x-audio')\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65755c4-ae67-4a71-bede-fb0225999452",
   "metadata": {},
   "source": [
    "First play the audio file we gonna transcibe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8336e-da34-463e-aa36-ab3d4fd599d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "\n",
    "# Load and play\n",
    "audio, sr = librosa.load(\"mlk.flac\")\n",
    "ipd.Audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f0623a-65bc-4219-ae64-f4b9515fbf61",
   "metadata": {},
   "source": [
    "Now execute transcirption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68133b-ae15-4180-89f4-6733edb28e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mlk.flac\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ecc36-df16-4e5f-972e-ab6688783313",
   "metadata": {},
   "source": [
    "## Cost performance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d2348-6d0f-416b-adf1-8152a9c71359",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = librosa.get_duration(path=\"mlk.flac\")\n",
    "print(f\"Audio duration: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781d93d-8996-4543-b0f2-4efb56871a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "iters = 10\n",
    "\n",
    "start = time.time()\n",
    "for i in range(0,iters):\n",
    "    predictor.predict(data)\n",
    "end = time.time()\n",
    "\n",
    "transcription_time = (end-start)/iters\n",
    "print(f\"Average transcription time: {transcription_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebd2d6-9459-4d89-b31e-1161ec06a9f4",
   "metadata": {},
   "source": [
    "Get pricing for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66254a-2e08-4731-a85f-56646400e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names = {\n",
    "    'us-east-1': 'US East (N. Virginia)',\n",
    "    'us-east-2': 'US East (Ohio)',\n",
    "    'us-west-1': 'US West (N. California)',\n",
    "    'us-west-2': 'US West (Oregon)',\n",
    "    'eu-west-1': 'Europe (Ireland)',\n",
    "    'eu-west-2': 'Europe (London)',\n",
    "    'eu-west-3': 'Europe (Paris)',\n",
    "    'eu-central-1': 'Europe (Frankfurt)',\n",
    "    'ap-southeast-1': 'Asia Pacific (Singapore)',\n",
    "    'ap-southeast-2': 'Asia Pacific (Sydney)',\n",
    "    'ap-northeast-1': 'Asia Pacific (Tokyo)',\n",
    "    # Add more as needed\n",
    "}\n",
    "\n",
    "# pricing api requires us-east-1 region\n",
    "pricing = boto3.client('pricing', region_name='us-east-1')\n",
    "\n",
    "response = pricing.get_products(\n",
    "    ServiceCode='AmazonSageMaker',\n",
    "    Filters=[\n",
    "        {'Type': 'TERM_MATCH', 'Field': 'instanceType', 'Value': instance_type},\n",
    "        {'Type': 'TERM_MATCH', 'Field': 'productFamily', 'Value': 'ML Instance'},\n",
    "        {'Type': 'TERM_MATCH', 'Field': 'location', 'Value': region_names[region]}\n",
    "    ]\n",
    ")\n",
    "\n",
    "import json\n",
    "data = json.loads(response['PriceList'][0])\n",
    "on_demand = data['terms']['OnDemand']\n",
    "first_term = next(iter(on_demand.values()))\n",
    "first_dimension = next(iter(first_term['priceDimensions'].values()))\n",
    "price = float(first_dimension['pricePerUnit']['USD'])\n",
    "print(f\"Price per hour for {instance_type}: {price} USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b28ed-4449-4950-b984-f6eeb589c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_to_transcribe_1_sec = price / (3600.0/transcription_time*duration)\n",
    "print(f\"Cost to transcribe 1 second of audio using Whisper on {instance_type}: {price_to_transcribe_1_sec} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634c6313-68e4-484c-800d-34feb556a6d8",
   "metadata": {},
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28010b5-dd3d-4303-a4a1-308ad3e86b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c109c-bd26-4c55-99c8-7bbc5e2a36ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00231563-f999-432e-8dc1-9d2a5b8336b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
